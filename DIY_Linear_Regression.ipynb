{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524765b-66be-4ff6-b697-f0a13fc3b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import clean data \n",
    "path = 'https://raw.githubusercontent.com/andresmorenoviteri/ML-models/main/CarPrice_Assignment.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555421f-03a0-49ab-aff5-93500bb740b1",
   "metadata": {},
   "source": [
    "First, let's only use numeric data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b40bd0-2061-4206-a189-29d01f8162e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df._get_numeric_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310cd86-8e7a-40f8-9a40-46cfad5d4cb7",
   "metadata": {},
   "source": [
    "## Part 1: Training and Testing\n",
    "\n",
    "The first step into training and testing a model is to split the data into a training and testing data set. Since our target is to predict the 'price', we will named this **y_data** and the dependent parameters will be named **x_data**\n",
    "\n",
    "since we want all the other parameters in df except 'price', we can drop it from the dataframe using:\n",
    "\n",
    "    df.drop('parameter', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe224a-4162-4fb4-99f2-314eaa6646bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = ____\n",
    "\n",
    "x_data = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699c5cf-c12c-4fe3-97c1-388ea1981e58",
   "metadata": {},
   "source": [
    "Now, we randomly split our data into training and testing data using the function **train_test_split**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776310c3-6957-4fe2-be26-f6b720f90736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = ____\n",
    "\n",
    "print(\"training samples:\",x_train.shape[0])\n",
    "print(\"test samples:\", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6109fd0e-c147-40ca-b5e5-f4744024a8e8",
   "metadata": {},
   "source": [
    "The **test_size** parameter sets the percentage of data that is split for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771563ee-61ff-4c90-879a-a1a1ec7a54e2",
   "metadata": {},
   "source": [
    "Let's import **LinearRegression** from the module **linear_model**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac6913-3c74-4cb9-8778-8c58b39e79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to start with a **simple linear regression**, therefore we check which of our features has the highest correlation with the 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the parameter 'enginesize' has the highest correlation with the 'price'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04915994-2bf2-489d-b50a-b460a96f8079",
   "metadata": {},
   "source": [
    "We create a Linear Regression object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf8615-85c9-42ef-8622-d99a9af6e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre=____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3858b785-ba40-48ec-aed2-cb204012cc2e",
   "metadata": {},
   "source": [
    "We fit the model using the feature \"enginesize\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663855d-c932-475c-b81f-f9a50a50c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac9890-f456-46d0-a0da-f8945e8d0f26",
   "metadata": {},
   "source": [
    "Let's calculate the R^2 on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930c700-1c39-4c9d-8f7f-1b5bc1f5b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the R^2 on the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f0f931-b9c8-454d-af87-d24a5637e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 for the training data is bigger than for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d238f4-4d10-4819-897d-3ec9c913bf84",
   "metadata": {},
   "source": [
    "## Cross-Validation Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f549e18-b514-4f0e-ba7d-4dc0cad5dfe7",
   "metadata": {},
   "source": [
    "Let's import **cross_val_score** from the module **model_selection**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b382fe-420c-4f02-9479-cab9e06dfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea3d0e-750b-47ac-bbc6-87113e7be457",
   "metadata": {},
   "source": [
    "We input the object, the feature 'enginesize', and the target data 'y_data'. The parameter 'cv' determines the number of folds. let's test 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2ff73-a3c3-44ea-befe-7ea149d19361",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7b4da-bd4d-43a1-aef4-6a3929a952f3",
   "metadata": {},
   "source": [
    "The default scoring is R^2. Each element in the array has the average R^2 value for the fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f93927-f917-436e-b892-6d2a89d92b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5be831-b81c-43b7-b4c7-37dffcaf7772",
   "metadata": {},
   "source": [
    " We can calculate the average and standard deviation of our estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc5f90-f0b1-421d-b493-fe5a3456629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean of the folds are {round(Rcross.mean(), 2)} and the standard deviation is {round(Rcross.std(), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7e373c-33a8-46da-a017-ae9743f0a6a1",
   "metadata": {},
   "source": [
    "We can use negative squared error as a score by setting the parameter  'scoring' metric to 'neg_mean_squared_error'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b6461-58cb-4e23-9154-5451ecd6eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "-1 * cross_val_score(lre,x_data[['enginesize']], y_data,cv=4,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac669ea-2c44-4ad7-9308-a56487d60e21",
   "metadata": {},
   "source": [
    "You can also use the function 'cross_val_predict' to predict the output. The function splits up the data into the specified number of folds, with one fold for testing and the other folds are used for training. First, import the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181eae80-1d99-4b48-8b23-6cf14f8cad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4396a6-9c7e-4999-a7ae-892aee4a935a",
   "metadata": {},
   "source": [
    "We input the object, the feature **\"enginesize\"**, and the target data **y_data**. The parameter 'cv' determines the number of folds. In this case, it is 4. We can produce an output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba835c-991b-4059-ba67-48fb5082b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = ____\n",
    "yhat[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850196d-072a-4484-bcc4-bdaae8b7cfee",
   "metadata": {},
   "source": [
    "## Part 2: Overfitting, Underfitting and Model Selection\n",
    "\n",
    "The test data, often called **out-of-sample data** gives a more accurate picture of how your model will perform on real-world data. This is because it helps reveal issues like overfitting, where a model fits the training data too closely and fails to generalize.\n",
    "\n",
    "We’ll look at some examples to illustrate this. The effects of **overfitting** are especially noticeable in **Multiple Linear Regression** and **Polynomial Regression**, so we’ll focus on those cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9210e26-9e07-449f-8aed-fb3683a8335d",
   "metadata": {},
   "source": [
    "Let's create Multiple Linear Regression objects and train the model using **'curbweight'**, **'enginesize'** and **'horsepower'** as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0737e-61fa-47c5-90f0-c8165ebad949",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ____\n",
    "lr.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a02a90-0ac7-42dd-ab89-7a8961b7f051",
   "metadata": {},
   "source": [
    "Prediction using training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482b65e-56d2-4b0c-b020-21875e924f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = ____\n",
    "yhat_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the distribution of the predicted values of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributionPlot(ytarget, ypred, title, ytargetLabel):\n",
    "    sns.kdeplot(ytarget, label=ytargetLabel)\n",
    "    sns.kdeplot(ypred, label='predicted data')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Proportion of cars')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributionPlot(ytarget=y_train, ypred=yhat_train, title='Distribution Plot of Predicted Value Using Training Data and its Target Value', ytargetLabel='training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to be doing well in learning from the training dataset. But we are interested in seeing how the model performs with never before seen data, therefore we do predictions on the test data and compare with its actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f3424-f53f-466a-aae0-c72fcbcc8162",
   "metadata": {},
   "source": [
    "Prediction using test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78959675-9f61-431a-88ce-34b97ce7b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = lr.predict(x_test[['curbweight', 'enginesize', 'horsepower']])\n",
    "yhat_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3802c-8b6c-4e9f-b0b9-da4606c65801",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributionPlot(ytarget=y_test, ypred=yhat_test, title='Distribution Plot of Predicted Value Using Test Data and its Target Value', ytargetLabel='test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a257cc-36bd-4665-bcfc-24028b694792",
   "metadata": {},
   "source": [
    "Comparing the Training plot and and the Test plot, it is evident that the distribution of the training data  is much better at fitting the data. This difference in the Test plot is apparent in the range of 5000 to 15,000. This is where the shape of the distribution is extremely different. Let's see if polynomial regression also exhibits a drop in the prediction accuracy when analysing the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799599d-2998-44df-80fa-ab015d8afa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f57b56-d8d5-4f3c-99b5-6e7c9a84cdf0",
   "metadata": {},
   "source": [
    "#### Overfitting\n",
    "Overfitting occurs when the model fits the noise, but not the underlying process. Therefore, when testing your model using the test set, your model does not perform as well since it is modelling noise, not the underlying process that generated the relationship. Let's create a degree 2 polynomial model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf1fb8-02ee-4fcc-9d57-99f9e2c090ec",
   "metadata": {},
   "source": [
    "Let's use 55 percent of the data for training and the rest for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feca416-a414-4d6d-b428-e9bc1cb06a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317f47f-6481-482a-81bc-a48f7eca9286",
   "metadata": {},
   "source": [
    "We will perform a degree 2 polynomial transformation on the feature 'enginesize'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc9064-5ef0-4753-a4e3-ff124e33195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = ____\n",
    "x_train_pr = ____\n",
    "x_test_pr = _____\n",
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb6c4e-b946-48df-be5f-b9d9548ce25f",
   "metadata": {},
   "source": [
    "Now, let's create a Linear Regression model \"poly\" and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20bc7e-0a56-417c-8a7b-d33748dbabd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = LinearRegression()\n",
    "poly.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c9eb8-a08f-46bb-9da3-034cd30bc6d9",
   "metadata": {},
   "source": [
    "We can see the output of our model using the method \"predict.\" We assign the values to \"yhat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = poly.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0afd71c-dfd3-44af-b147-a9ae33c94447",
   "metadata": {},
   "source": [
    "Let's take the first five predicted values and compare it to the actual targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae9508-95f8-4442-a9f0-a0194e3cb4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted values:\", yhat[0:5])\n",
    "print(\"True values:\", y_test[0:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function \"polyplot\" to display the training data, testing data, and the predicted function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyplot(xtrain, ytrain, xtest, ytest, poly_feat, poly_reg):\n",
    "    x = xtrain\n",
    "    x_range = np.linspace(x.min(), x.max(), 200).reshape(-1, 1)\n",
    "    x_poly_range = pr.fit_transform(x_range)\n",
    "    y_range_pred = poly.predict(x_poly_range)\n",
    "    sns.scatterplot(x=xtrain, y=ytrain, label='Train data')\n",
    "    sns.scatterplot(x=xtest, y=ytest, label='Test data')\n",
    "    sns.lineplot(x=x_range.flatten(), y=y_range_pred, color='r', label='Prediction Function')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyplot(xtrain=x_train['enginesize'], ytrain=y_train, xtest=x_test['enginesize'], ytest=y_test, poly_feat=pr, poly_reg=poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b123e4-ed05-475d-97e2-14a482c39735",
   "metadata": {},
   "source": [
    "A polynomial regression model where blue dots represent training data, orange dots represent test data, and the red line represents the model prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d5e98-ae4b-4b57-a800-426be5e9b6ff",
   "metadata": {},
   "source": [
    "We see that the estimated function appears to track the data but around an enginesize of 270, the function begins to diverge from the data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a4e2c-1fe9-437d-9348-26a52a840c4a",
   "metadata": {},
   "source": [
    "R^2 of the training data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92add389-fa5d-4003-88c3-2ed42d6a8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f407ef8-41b0-4c64-b641-929a11033cfb",
   "metadata": {},
   "source": [
    " R^2 of the test data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62035783-82cd-4d3b-b4b7-21b2f1f2b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a86178-4446-4bdf-946d-6723c699ec98",
   "metadata": {},
   "source": [
    "We see the R^2 for the training data is 0.775 while the R^2 on the test data was 0.734.  The lower the R^2, the worse the model. A negative R^2 is a sign of overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195257e-ab8e-44f6-9cf9-0016474aec53",
   "metadata": {},
   "source": [
    "Let's see how the R^2 changes on the test data for different order polynomials and then plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89850c44-19a3-4a15-a870-cc666072a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rsqu_test = []\n",
    "\n",
    "order = [1, 2, 3, 4, 5]\n",
    "for n in order:\n",
    "    pr = PolynomialFeatures(degree=n)\n",
    "    \n",
    "    x_train_pr = pr.fit_transform(x_train[['enginesize']])\n",
    "    \n",
    "    x_test_pr = pr.fit_transform(x_test[['enginesize']])    \n",
    "    \n",
    "    lr.fit(x_train_pr, y_train)\n",
    "    \n",
    "    Rsqu_test.append(lr.score(x_test_pr, y_test))\n",
    "\n",
    "plt.plot(order, Rsqu_test)\n",
    "plt.xlabel('order')\n",
    "plt.ylabel('R^2')\n",
    "plt.title('R^2 Using Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76422a9a-5203-4328-a43f-e50e158f6943",
   "metadata": {},
   "source": [
    "We see the R^2 gradually increases until an order three polynomial is used. Then, the R^2 continously decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff25ba3-2f2e-42c1-9adb-6e59f265629b",
   "metadata": {},
   "source": [
    "We can perform polynomial transformations with more than one feature. Create a **PolynomialFeatures** object **pf** of degree three using\n",
    "`carwidth`, `curbweight`, `enginesize`, `horsepower`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f92b7-ae9f-4ad6-8d4b-e6c2dc6dce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n",
    "pf = ____\n",
    "x_train_pf = ____\n",
    "x_test_pf = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b97ef-5cd3-47a7-848b-213352452caa",
   "metadata": {},
   "source": [
    "How many dimensions does the new feature have? Hint: use the attribute \"shape\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30167a-0811-4a82-b89c-d0083f45dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n",
    "x_train_pf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a059c14-ce7a-44aa-9de8-209e4c850aaa",
   "metadata": {},
   "source": [
    "Create a linear regression model \"polyreg1\". Train the object using the method \"fit\" using the polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959e40a-a729-42f5-a8e7-3addab55def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n",
    "polyreg1 = ____\n",
    "polyreg1.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1f1bf-5277-4820-b856-17fbce609e85",
   "metadata": {},
   "source": [
    "Use the method  \"predict\" to predict an output on the polynomial features, then use the function \"distributionPlot\" to display the distribution of the predicted test output vs. the actual test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6f235-6064-452b-bdf8-1e3a2c54df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n",
    "yhat_test = polyreg1.____\n",
    "\n",
    "distributionPlot(ytarget=y_test, ypred=yhat_test, title='Distribution Plot of Predicted Value Using Test Data vs Test Data Value of polyreg 2', ytargetLabel='test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0dd34f-25e5-436b-ab6b-b29778d7bc97",
   "metadata": {},
   "source": [
    "Using the distribution plot above, describe (in words) the two regions where the predicted prices are less accurate than the actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee7faa-598d-4f9e-a57c-13df4a38d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7abe92-14f3-4fdf-b995-2936c2c08576",
   "metadata": {},
   "source": [
    "## Part 3: Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14d2f7-774e-40cd-919c-f3dc00aaa164",
   "metadata": {},
   "source": [
    " In this section, we will review Ridge Regression and see how the parameter alpha changes the model. Just a note, here our test data will be used as validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd69f75-ce26-4a1a-9f69-7ac490c42dd9",
   "metadata": {},
   "source": [
    "Let's perform a degree two polynomial transformation on the parameters:\n",
    "`curbweight`, `enginesize`, `boreratio`, `horsepower`, `highwaympg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91373318-62aa-4c74-ba76-ad1077120c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ____\n",
    "x_train_pr = pf.____\n",
    "x_test_pr = pf.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cff430-f5b4-4a5f-bbf3-df6de5768983",
   "metadata": {},
   "source": [
    " Let's import  **Ridge**  from the module **linear models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08059112-ccd8-4c8a-9f3b-c7a025793f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ae769-f228-48f0-8920-a3b52e630da5",
   "metadata": {},
   "source": [
    "Let's create a Ridge regression object, setting the regularization parameter (alpha) to 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad86e2d-51ff-42d2-a704-450ab9dfdb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeModel=____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c21ecf-321b-4ae8-a2a1-298139aff9af",
   "metadata": {},
   "source": [
    "Like regular regression, you can fit the model using the method fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e947f8-16ca-4101-8b62-0443fdff0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeModel.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0732a4e-cbb1-46fc-86e7-7d3f0000b0eb",
   "metadata": {},
   "source": [
    "Similarly, you can obtain a prediction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b9cc6-889d-4ecb-9e3f-30c9e9deb359",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = _____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37d949-d67b-4633-966a-627359cdbc45",
   "metadata": {},
   "source": [
    "Let's compare the first four predicted samples to our test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d376f-f7ed-4980-892f-609ef7c568a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predicted:', yhat[0:4])\n",
    "print('test set :', y_test[0:4].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd009f95-1095-4061-a6f3-8fa46358b2c5",
   "metadata": {},
   "source": [
    "We select the value of alpha that minimizes the test error. To do so, we can use a for loop. We have also created a progress bar to see how many iterations we have completed so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb536fe-8003-4213-a616-6a31c1830ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "Rsqu_test = []\n",
    "Rsqu_train = []\n",
    "dummy1 = []\n",
    "Alpha = np.array(range(0,1000,1))\n",
    "pbar = tqdm(Alpha)\n",
    "\n",
    "for alpha in pbar:\n",
    "    ridgeModel = Ridge(alpha=alpha) \n",
    "    ridgeModel.fit(x_train_pr, y_train)\n",
    "    test_score, train_score = ridgeModel.score(x_test_pr, y_test), ridgeModel.score(x_train_pr, y_train)\n",
    "    \n",
    "    pbar.set_postfix({\"Test Score\": test_score, \"Train Score\": train_score})\n",
    "\n",
    "    Rsqu_test.append(test_score)\n",
    "    Rsqu_train.append(train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a88e00-fbea-4a4c-95e2-9ea34af3b7f0",
   "metadata": {},
   "source": [
    "We can plot out the value of R^2 for different alphas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e0918-edac-4afd-a9d2-240b84e80a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 6\n",
    "height = 5\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(Alpha,Rsqu_test, label='validation data  ')\n",
    "plt.plot(Alpha,Rsqu_train, 'r', label='training Data ')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rsq = 0\n",
    "max_id = 0\n",
    "for idx, val in enumerate(Rsqu_test):\n",
    "    if val > max_rsq:\n",
    "        max_rsq = val\n",
    "        max_id = Alpha[idx]\n",
    "\n",
    "print(f\"max alpha: {max_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e520fbe5-df77-48bb-8eab-e6a657aed68f",
   "metadata": {},
   "source": [
    "**Figure 4**: The blue line represents the R^2 of the validation data, and the red line represents the R^2 of the training data. The x-axis represents the different values of Alpha. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df3eb14-185a-4985-b1f8-90637e0699e5",
   "metadata": {},
   "source": [
    "Here the model is built and tested on the same data, so the training and test data are the same.\n",
    "\n",
    "The red line in Figure 4 represents the R^2 of the training data. As alpha increases the R^2 decreases. Therefore, as alpha increases, the model performs worse on the training data\n",
    "\n",
    "The blue line represents the R^2 on the validation data. As the value for alpha increases, the R^2 increases and converges at a point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781eb541-1c42-43d2-8820-c5a645b46c82",
   "metadata": {},
   "source": [
    "Perform Ridge regression. Calculate the R^2 using the polynomial features, use the training data to train the model and use the test data to test the model. The parameter alpha should be set to max_alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11c367-faa8-45f3-a0f4-b670f27454ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n",
    "ridgeModel = ____\n",
    "ridgeModel.____\n",
    "ridgeModel.____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ceea9-c65d-4096-b22d-cd0f938f7207",
   "metadata": {},
   "source": [
    "## Part 4: Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0453511e-cddf-4c63-a35a-734dbcec81d6",
   "metadata": {},
   "source": [
    "The term alpha is a hyperparameter. Sklearn has the class **GridSearchCV** to make the process of finding the best hyperparameter simpler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb04bb-9170-46ed-bda6-82a2f9d5e8b5",
   "metadata": {},
   "source": [
    "Let's import **GridSearchCV** from  the module **model_selection**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ddcd5-d3cf-4c83-8ebc-0cbe16262b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3eac4b-fba8-4386-98cb-4ba81d6abc10",
   "metadata": {},
   "source": [
    "We create a a pipeline for the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('ridge', Ridge())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters of the pipeline. `poly__degree` and `ridge__alpha`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646493f-884d-4b5e-ae00-5bce30eb06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = ____\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(____)\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV R² score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model to predict\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.score(x_test[['enginesize', 'horsepower']], y_test)\n",
    "#y_pred = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch Venv",
   "language": "python",
   "name": "torch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
